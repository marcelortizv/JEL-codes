{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries and functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def extend_list(tags):\n",
    "    retlist = []\n",
    "    for tag in tags:\n",
    "        retlist.extend(tag)\n",
    "    return set(retlist)\n",
    "\n",
    "def Accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy based on Jaccard Similarity Score\n",
    "    :param y_true: ground truth\n",
    "    :param y_pred: prediction\n",
    "    :return: Jaccard Similarity Score\n",
    "    \"\"\"\n",
    "    jaccard = np.minimum(y_true, y_pred).sum(axis=1) / np.maximum(y_true, y_pred).sum(axis=1)\n",
    "    return jaccard.mean()\n",
    "\n",
    "\n",
    "def print_ml_score(y_test, y_pred, clf):\n",
    "    print('Classifier: ', clf.__class__.__name__)\n",
    "    print('Accuracy Score: {}'.format(Accuracy(y_test, y_pred)))\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label_train, feature_vector_test, label_test):\n",
    "    # fit the training set on the classifier\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(feature_vector_train, label_train)\n",
    "\n",
    "    # predict the labels on test set\n",
    "    predictions = clf.predict(feature_vector_test)\n",
    "    #print(pd.DataFrame(predictions, columns = multilabel.classes_))\n",
    "    return print_ml_score(label_test, predictions, classifier)\n",
    "\n",
    "def get_vec(x):\n",
    "    doc = nlp(x)\n",
    "    vec = doc.vector\n",
    "    return vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "authors = pd.read_csv(\"../data/coauthor_list.csv\")\n",
    "authors.tags = authors.tags.apply(lambda tag: ast.literal_eval(tag))\n",
    "authors.idauthor = authors.idauthor.apply(lambda author: author.replace(\" \", \"\"))\n",
    "\n",
    "# keep JEL code different from letter Y, A and B\n",
    "\n",
    "#authors['keep'] = authors.tags.apply(lambda tags: 'Y' not in tags)\n",
    "#authors = authors[authors.keep == True]\n",
    "#authors\n",
    "\n",
    "authors['keep'] = authors.tags.apply(lambda tags: 'Y' not in tags)\n",
    "authors = authors[authors.keep == True]\n",
    "authors['keep'] = authors.tags.apply(lambda tags: 'A' not in tags)\n",
    "authors = authors[authors.keep == True]\n",
    "authors['keep'] = authors.tags.apply(lambda tags: 'B' not in tags)\n",
    "authors = authors[authors.keep == True]\n",
    "authors.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "           tags                                              title idauthor  \\\n0  [O, D, G, E]     optimal adoption of complementary technologies   p00681   \n0  [O, D, G, E]     optimal adoption of complementary technologies   p01338   \n1        [G, E]  collateral damage: effects of the japanese ban...   p01546   \n1        [G, E]  collateral damage: effects of the japanese ban...   p02544   \n2           [J]  endogenous inequality in integrated labor mark...   p00544   \n\n               author  keep  \n0     boyan jovanovic  True  \n0   dmitriy stolyarov  True  \n1      eric rosengren  True  \n1            joe peek  True  \n2        avner shaked  True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>title</th>\n      <th>idauthor</th>\n      <th>author</th>\n      <th>keep</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[O, D, G, E]</td>\n      <td>optimal adoption of complementary technologies</td>\n      <td>p00681</td>\n      <td>boyan jovanovic</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[O, D, G, E]</td>\n      <td>optimal adoption of complementary technologies</td>\n      <td>p01338</td>\n      <td>dmitriy stolyarov</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[G, E]</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>p01546</td>\n      <td>eric rosengren</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[G, E]</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>p02544</td>\n      <td>joe peek</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[J]</td>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>p00544</td>\n      <td>avner shaked</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "authors_tags = authors.groupby(\"idauthor\").agg({\"tags\": lambda tags: list(extend_list(tags))})\n",
    "authors_tags['idauthor'] = authors_tags.index\n",
    "\n",
    "# keep JEL code different from letter Y, A and B\n",
    "\n",
    "#authors_tags['keep'] = authors_tags.tags.apply(lambda tags: 'Y' not in tags)\n",
    "#authors_tags = authors_tags[authors_tags.keep == True]\n",
    "#authors_tags\n",
    "\n",
    "authors_tags['keep'] = authors_tags.tags.apply(lambda tags: 'Y' not in tags)\n",
    "authors_tags = authors_tags[authors_tags.keep == True]\n",
    "authors_tags['keep'] = authors_tags.tags.apply(lambda tags: 'A' not in tags)\n",
    "authors_tags = authors_tags[authors_tags.keep == True]\n",
    "authors_tags['keep'] = authors_tags.tags.apply(lambda tags: 'B' not in tags)\n",
    "authors_tags = authors_tags[authors_tags.keep == True]\n",
    "authors.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "           tags                                              title idauthor  \\\n0  [O, D, G, E]     optimal adoption of complementary technologies   p00681   \n0  [O, D, G, E]     optimal adoption of complementary technologies   p01338   \n1        [G, E]  collateral damage: effects of the japanese ban...   p01546   \n1        [G, E]  collateral damage: effects of the japanese ban...   p02544   \n2           [J]  endogenous inequality in integrated labor mark...   p00544   \n\n               author  keep  \n0     boyan jovanovic  True  \n0   dmitriy stolyarov  True  \n1      eric rosengren  True  \n1            joe peek  True  \n2        avner shaked  True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>title</th>\n      <th>idauthor</th>\n      <th>author</th>\n      <th>keep</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[O, D, G, E]</td>\n      <td>optimal adoption of complementary technologies</td>\n      <td>p00681</td>\n      <td>boyan jovanovic</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[O, D, G, E]</td>\n      <td>optimal adoption of complementary technologies</td>\n      <td>p01338</td>\n      <td>dmitriy stolyarov</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[G, E]</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>p01546</td>\n      <td>eric rosengren</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[G, E]</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>p02544</td>\n      <td>joe peek</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[J]</td>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>p00544</td>\n      <td>avner shaked</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# creating  dictionary for the authors and its tags\n",
    "authors_dict = {}\n",
    "for i, row in authors_tags.iterrows():\n",
    "\n",
    "    authors_dict[row.idauthor] = {\"tags\": row.tags, \"hasConnection\": []}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(authors['tags'])\n",
    "pd.DataFrame(y, columns = multilabel.classes_)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "      C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  Z\n0     0  1  1  0  1  0  0  0  0  0  0  0  1  0  0  0  0\n1     0  1  1  0  1  0  0  0  0  0  0  0  1  0  0  0  0\n2     0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n3     0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n4     0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n7110  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n7111  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0\n7112  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0\n7113  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0\n7114  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0\n\n[7115 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>J</th>\n      <th>K</th>\n      <th>L</th>\n      <th>M</th>\n      <th>N</th>\n      <th>O</th>\n      <th>P</th>\n      <th>Q</th>\n      <th>R</th>\n      <th>Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7110</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7111</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7112</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7113</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7114</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7115 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# grouping author by title of paper\n",
    "papers_grouped = authors.groupby(\"title\").agg({\"idauthor\": lambda authors: list(authors)})\n",
    "papers_grouped['title'] = papers_grouped.index\n",
    "papers_grouped.index = range(len(papers_grouped))\n",
    "papers_grouped\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                      idauthor  \\\n0     [p01714, p02726, p03637]   \n1     [p00226, p03171, p05209]   \n2     [p00198, p02336, p02575]   \n3             [p05429, p05611]   \n4             [p01353, p04127]   \n...                        ...   \n3085                  [p00122]   \n3086  [p00381, p04476, p05132]   \n3087                  [p04412]   \n3088          [p04020, p05368]   \n3089  [p00198, p01842, p04614]   \n\n                                                  title  \n0     $1,000 cash back: the pass-through of auto man...  \n1     'acting wife': marriage market incentives and ...  \n2     (mis)allocation, market power, and global oil ...  \n3           a bayesian approach to uncertainty aversion  \n4     a bias–reduced log–periodogram regression esti...  \n...                                                 ...  \n3085  yours, mine, and ours: do divorce laws affect ...  \n3086  zombie lending and depressed restructuring in ...  \n3087  “data monkeys”: a procedural model of extrapol...  \n3088  “high” achievers? cannabis access and academic...  \n3089  “nash-in-nash” bargaining: a microfoundation f...  \n\n[3090 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idauthor</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[p01714, p02726, p03637]</td>\n      <td>$1,000 cash back: the pass-through of auto man...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[p00226, p03171, p05209]</td>\n      <td>'acting wife': marriage market incentives and ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[p00198, p02336, p02575]</td>\n      <td>(mis)allocation, market power, and global oil ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[p05429, p05611]</td>\n      <td>a bayesian approach to uncertainty aversion</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[p01353, p04127]</td>\n      <td>a bias–reduced log–periodogram regression esti...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3085</th>\n      <td>[p00122]</td>\n      <td>yours, mine, and ours: do divorce laws affect ...</td>\n    </tr>\n    <tr>\n      <th>3086</th>\n      <td>[p00381, p04476, p05132]</td>\n      <td>zombie lending and depressed restructuring in ...</td>\n    </tr>\n    <tr>\n      <th>3087</th>\n      <td>[p04412]</td>\n      <td>“data monkeys”: a procedural model of extrapol...</td>\n    </tr>\n    <tr>\n      <th>3088</th>\n      <td>[p04020, p05368]</td>\n      <td>“high” achievers? cannabis access and academic...</td>\n    </tr>\n    <tr>\n      <th>3089</th>\n      <td>[p00198, p01842, p04614]</td>\n      <td>“nash-in-nash” bargaining: a microfoundation f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3090 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for i, row in papers_grouped.iterrows():\n",
    "    for author in row.idauthor:\n",
    "        authors_dict[author]['hasConnection'].extend(set(row.idauthor).difference({author}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for author in authors_dict:\n",
    "    authors_dict[author]['hasConnection'] = list(set(authors_dict[author]['hasConnection']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# example with author \"p00062\"\n",
    "authors_dict[authors_dict[\"p00062\"][\"hasConnection\"][0]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "{'tags': ['G', 'J', 'D', 'C'], 'hasConnection': ['p03719', 'p00062']}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# found all JELcodes from coauthors\n",
    "for author in authors_dict:\n",
    "    new_tags = []\n",
    "    for connected_author in authors_dict[author]['hasConnection']:\n",
    "        new_tags.extend(authors_dict[connected_author][\"tags\"])\n",
    "    new_tags = list(set(new_tags))\n",
    "    authors_dict[author][\"level1_tags\"] = new_tags\n",
    "    authors_dict[author][\"level1_tags\"].extend(authors_dict[author]['tags'])\n",
    "    authors_dict[author][\"level1_tags\"] = list(set(authors_dict[author][\"level1_tags\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# example with author p00062\n",
    "authors_dict[authors_dict[\"p00062\"][\"hasConnection\"][0]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "{'tags': ['G', 'J', 'D', 'C'],\n 'hasConnection': ['p03719', 'p00062'],\n 'level1_tags': ['G', 'D', 'J', 'C']}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# length of JELcodes by author\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_tags = []\n",
    "for author in authors_dict:\n",
    "    n_tags.append(len(authors_dict[author][\"level1_tags\"]))\n",
    "\n",
    "_ = plt.hist(n_tags)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# converting tags in one-hot encoding\n",
    "for author in authors_dict:\n",
    "    authors_dict[author][\"coded_tags\"] = np.sum(multilabel.transform(authors_dict[author][\"level1_tags\"]), axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# example with author p00062\n",
    "authors_dict[authors_dict[\"p00062\"][\"hasConnection\"][0]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "{'tags': ['G', 'J', 'D', 'C'],\n 'hasConnection': ['p03719', 'p00062'],\n 'level1_tags': ['G', 'D', 'J', 'C'],\n 'coded_tags': array([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# creating a author dataframe with connections (graphframe)\n",
    "authors_graphframe = pd.DataFrame(authors_dict)\n",
    "authors_graphframe = authors_graphframe.T\n",
    "authors_graphframe['idauthor'] = authors_graphframe.index\n",
    "authors_graphframe.to_csv('../data/couathor_graphframe_v02.csv', index=False)\n",
    "authors_graphframe.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                tags             hasConnection                  level1_tags  \\\np00001     [I, H, O]  [p02522, p00075, p02923]        [D, O, H, I, M, J, C]   \np00003           [H]                  [p04319]                          [H]   \np00004     [E, F, O]  [p03521, p04645, p01781]  [E, D, O, F, N, R, J, C, G]   \np00006  [G, F, P, O]                  [p00511]                 [G, F, P, O]   \np00008     [I, J, O]          [p00110, p02923]           [O, H, I, M, J, C]   \n\n                                               coded_tags idauthor  \np00001  [1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, ...   p00001  \np00003  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   p00003  \np00004  [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, ...   p00004  \np00006  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...   p00006  \np00008  [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, ...   p00008  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>hasConnection</th>\n      <th>level1_tags</th>\n      <th>coded_tags</th>\n      <th>idauthor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>p00001</th>\n      <td>[I, H, O]</td>\n      <td>[p02522, p00075, p02923]</td>\n      <td>[D, O, H, I, M, J, C]</td>\n      <td>[1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, ...</td>\n      <td>p00001</td>\n    </tr>\n    <tr>\n      <th>p00003</th>\n      <td>[H]</td>\n      <td>[p04319]</td>\n      <td>[H]</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>p00003</td>\n    </tr>\n    <tr>\n      <th>p00004</th>\n      <td>[E, F, O]</td>\n      <td>[p03521, p04645, p01781]</td>\n      <td>[E, D, O, F, N, R, J, C, G]</td>\n      <td>[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, ...</td>\n      <td>p00004</td>\n    </tr>\n    <tr>\n      <th>p00006</th>\n      <td>[G, F, P, O]</td>\n      <td>[p00511]</td>\n      <td>[G, F, P, O]</td>\n      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n      <td>p00006</td>\n    </tr>\n    <tr>\n      <th>p00008</th>\n      <td>[I, J, O]</td>\n      <td>[p00110, p02923]</td>\n      <td>[O, H, I, M, J, C]</td>\n      <td>[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, ...</td>\n      <td>p00008</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Machine Learning + Network Co-authorship"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../data/traning_data_cleaned_v03.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#df.author = df.author.apply(lambda author: author.replace(\" \",\"\"))\n",
    "#df = df[[\"title_x\", \"abstract\", \"tags\", \"idauthor\"]]\n",
    "df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "df['keep'] = df.tags.apply(lambda tags: 'Y' not in tags)\n",
    "df = df[df.keep == True]\n",
    "df['keep'] = df.tags.apply(lambda tags: 'A' not in tags)\n",
    "df = df[df.keep == True]\n",
    "df['keep'] = df.tags.apply(lambda tags: 'B' not in tags)\n",
    "df = df[df.keep == True]\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                                             title_x  \\\n0     optimal adoption of complementary technologies   \n1  collateral damage: effects of the japanese ban...   \n2  endogenous inequality in integrated labor mark...   \n3  labor-market integration, investment in risky ...   \n4  unequal societies: income distribution and the...   \n\n                                            abstract          tags  \\\n0  When a production process requires two extreme...  [O, D, G, E]   \n1  The Japanese banking crisis provides a natural...        [G, E]   \n2  We consider a market with red and green worker...           [J]   \n3  This paper presents a general-equilibrium mode...        [J, R]   \n4  This paper develops a theory of inequality and...  [P, E, I, D]   \n\n                         idauthor  \\\n0            ['p00681', 'p01338']   \n1            ['p01546', 'p02544']   \n2  ['p00544', 'p01874', 'p03092']   \n3                      ['p01266']   \n4                      ['p04639']   \n\n                                            all_text  \\\n0  optimal adoption of complementary technologies...   \n1  collateral damage: effects of the japanese ban...   \n2  endogenous inequality in integrated labor mark...   \n3  labor-market integration, investment in risky ...   \n4  unequal societies: income distribution and the...   \n\n                                    cleaned_abstract  \\\n0  production process require two extremely compl...   \n1  japanese bank crisis provide natural experimen...   \n2  consider market red green workers  label payof...   \n3  present general-equilibrium human capital inve...   \n4  develop theory inequality social contract aim ...   \n\n                                    cleaned_all_text  keep  \n0  optimal adoption complementary technologies pr...  True  \n1  collateral damage  effect japanese bank crisis...  True  \n2  endogenous inequality integrate labor market t...  True  \n3  labor-market integration  investment risky hum...  True  \n4  unequal societies  income distribution social ...  True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_x</th>\n      <th>abstract</th>\n      <th>tags</th>\n      <th>idauthor</th>\n      <th>all_text</th>\n      <th>cleaned_abstract</th>\n      <th>cleaned_all_text</th>\n      <th>keep</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>optimal adoption of complementary technologies</td>\n      <td>When a production process requires two extreme...</td>\n      <td>[O, D, G, E]</td>\n      <td>['p00681', 'p01338']</td>\n      <td>optimal adoption of complementary technologies...</td>\n      <td>production process require two extremely compl...</td>\n      <td>optimal adoption complementary technologies pr...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>The Japanese banking crisis provides a natural...</td>\n      <td>[G, E]</td>\n      <td>['p01546', 'p02544']</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>japanese bank crisis provide natural experimen...</td>\n      <td>collateral damage  effect japanese bank crisis...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>We consider a market with red and green worker...</td>\n      <td>[J]</td>\n      <td>['p00544', 'p01874', 'p03092']</td>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>consider market red green workers  label payof...</td>\n      <td>endogenous inequality integrate labor market t...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>labor-market integration, investment in risky ...</td>\n      <td>This paper presents a general-equilibrium mode...</td>\n      <td>[J, R]</td>\n      <td>['p01266']</td>\n      <td>labor-market integration, investment in risky ...</td>\n      <td>present general-equilibrium human capital inve...</td>\n      <td>labor-market integration  investment risky hum...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>unequal societies: income distribution and the...</td>\n      <td>This paper develops a theory of inequality and...</td>\n      <td>[P, E, I, D]</td>\n      <td>['p04639']</td>\n      <td>unequal societies: income distribution and the...</td>\n      <td>develop theory inequality social contract aim ...</td>\n      <td>unequal societies  income distribution social ...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df['idauthor'] = df['idauthor'].apply(lambda authors: ast.literal_eval(authors)[0])\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                                             title_x  \\\n0     optimal adoption of complementary technologies   \n1  collateral damage: effects of the japanese ban...   \n2  endogenous inequality in integrated labor mark...   \n3  labor-market integration, investment in risky ...   \n4  unequal societies: income distribution and the...   \n\n                                            abstract          tags idauthor  \\\n0  When a production process requires two extreme...  [O, D, G, E]   p00681   \n1  The Japanese banking crisis provides a natural...        [G, E]   p01546   \n2  We consider a market with red and green worker...           [J]   p00544   \n3  This paper presents a general-equilibrium mode...        [J, R]   p01266   \n4  This paper develops a theory of inequality and...  [P, E, I, D]   p04639   \n\n                                            all_text  \\\n0  optimal adoption of complementary technologies...   \n1  collateral damage: effects of the japanese ban...   \n2  endogenous inequality in integrated labor mark...   \n3  labor-market integration, investment in risky ...   \n4  unequal societies: income distribution and the...   \n\n                                    cleaned_abstract  \\\n0  production process require two extremely compl...   \n1  japanese bank crisis provide natural experimen...   \n2  consider market red green workers  label payof...   \n3  present general-equilibrium human capital inve...   \n4  develop theory inequality social contract aim ...   \n\n                                    cleaned_all_text  keep  \n0  optimal adoption complementary technologies pr...  True  \n1  collateral damage  effect japanese bank crisis...  True  \n2  endogenous inequality integrate labor market t...  True  \n3  labor-market integration  investment risky hum...  True  \n4  unequal societies  income distribution social ...  True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_x</th>\n      <th>abstract</th>\n      <th>tags</th>\n      <th>idauthor</th>\n      <th>all_text</th>\n      <th>cleaned_abstract</th>\n      <th>cleaned_all_text</th>\n      <th>keep</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>optimal adoption of complementary technologies</td>\n      <td>When a production process requires two extreme...</td>\n      <td>[O, D, G, E]</td>\n      <td>p00681</td>\n      <td>optimal adoption of complementary technologies...</td>\n      <td>production process require two extremely compl...</td>\n      <td>optimal adoption complementary technologies pr...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>The Japanese banking crisis provides a natural...</td>\n      <td>[G, E]</td>\n      <td>p01546</td>\n      <td>collateral damage: effects of the japanese ban...</td>\n      <td>japanese bank crisis provide natural experimen...</td>\n      <td>collateral damage  effect japanese bank crisis...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>We consider a market with red and green worker...</td>\n      <td>[J]</td>\n      <td>p00544</td>\n      <td>endogenous inequality in integrated labor mark...</td>\n      <td>consider market red green workers  label payof...</td>\n      <td>endogenous inequality integrate labor market t...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>labor-market integration, investment in risky ...</td>\n      <td>This paper presents a general-equilibrium mode...</td>\n      <td>[J, R]</td>\n      <td>p01266</td>\n      <td>labor-market integration, investment in risky ...</td>\n      <td>present general-equilibrium human capital inve...</td>\n      <td>labor-market integration  investment risky hum...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>unequal societies: income distribution and the...</td>\n      <td>This paper develops a theory of inequality and...</td>\n      <td>[P, E, I, D]</td>\n      <td>p04639</td>\n      <td>unequal societies: income distribution and the...</td>\n      <td>develop theory inequality social contract aim ...</td>\n      <td>unequal societies  income distribution social ...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df_merged = df.merge(authors_graphframe, on='idauthor')\n",
    "df_merged.tail()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title_x  \\\n3087  the effect of product misperception on economi...   \n3088   house price beliefs and mortgage leverage choice   \n3089  the impact of consumer credit access on unempl...   \n3090                                   extended gravity   \n3091  deforestation in the amazon: a unified framewo...   \n\n                                               abstract        tags_x  \\\n3087  Panel and experimental data are used to analys...        [G, D]   \n3088  We study the relationship between homebuyers' ...  [D, R, G, E]   \n3089  Unemployed households' access to unsecured rev...     [J, G, E]   \n3090  Exporting firms often enter foreign markets th...        [L, F]   \n3091  Deforestation is a matter of pressing global c...        [L, Q]   \n\n     idauthor                                           all_text  \\\n3087   p02730  the effect of product misperception on economi...   \n3088   p01403  house price beliefs and mortgage leverage choi...   \n3089   p03070  the impact of consumer credit access on unempl...   \n3090   p00323  extended gravity Exporting firms often enter f...   \n3091   p01410  deforestation in the amazon: a unified framewo...   \n\n                                       cleaned_abstract  \\\n3087  panel experimental data use analyse economic o...   \n3088  study relationship homebuyers  beliefs future ...   \n3089  unemployed households  access unsecured revolv...   \n3090  export firm often enter foreign market similar...   \n3091  deforestation matter press global concern  yet...   \n\n                                       cleaned_all_text  keep        tags_y  \\\n3087  effect product misperception economic outcomes...  True        [G, D]   \n3088  house price beliefs mortgage leverage choice s...  True  [G, E, R, D]   \n3089  impact consumer credit access unemployment une...  True     [G, E, J]   \n3090  extend gravity export firm often enter foreign...  True        [F, L]   \n3091  deforestation amazon  unify framework estimati...  True        [Q, L]   \n\n                         hasConnection               level1_tags  \\\n3087                          [p05649]                    [G, D]   \n3088  [p02570, p03664, p05182, p00426]           [E, L, D, R, G]   \n3089                                []                 [G, J, E]   \n3090                  [p01408, p01944]  [E, L, D, F, H, R, J, C]   \n3091                                []                    [Q, L]   \n\n                                             coded_tags  \n3087  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3088  [0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n3089  [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n3090  [1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...  \n3091  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_x</th>\n      <th>abstract</th>\n      <th>tags_x</th>\n      <th>idauthor</th>\n      <th>all_text</th>\n      <th>cleaned_abstract</th>\n      <th>cleaned_all_text</th>\n      <th>keep</th>\n      <th>tags_y</th>\n      <th>hasConnection</th>\n      <th>level1_tags</th>\n      <th>coded_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3087</th>\n      <td>the effect of product misperception on economi...</td>\n      <td>Panel and experimental data are used to analys...</td>\n      <td>[G, D]</td>\n      <td>p02730</td>\n      <td>the effect of product misperception on economi...</td>\n      <td>panel experimental data use analyse economic o...</td>\n      <td>effect product misperception economic outcomes...</td>\n      <td>True</td>\n      <td>[G, D]</td>\n      <td>[p05649]</td>\n      <td>[G, D]</td>\n      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3088</th>\n      <td>house price beliefs and mortgage leverage choice</td>\n      <td>We study the relationship between homebuyers' ...</td>\n      <td>[D, R, G, E]</td>\n      <td>p01403</td>\n      <td>house price beliefs and mortgage leverage choi...</td>\n      <td>study relationship homebuyers  beliefs future ...</td>\n      <td>house price beliefs mortgage leverage choice s...</td>\n      <td>True</td>\n      <td>[G, E, R, D]</td>\n      <td>[p02570, p03664, p05182, p00426]</td>\n      <td>[E, L, D, R, G]</td>\n      <td>[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3089</th>\n      <td>the impact of consumer credit access on unempl...</td>\n      <td>Unemployed households' access to unsecured rev...</td>\n      <td>[J, G, E]</td>\n      <td>p03070</td>\n      <td>the impact of consumer credit access on unempl...</td>\n      <td>unemployed households  access unsecured revolv...</td>\n      <td>impact consumer credit access unemployment une...</td>\n      <td>True</td>\n      <td>[G, E, J]</td>\n      <td>[]</td>\n      <td>[G, J, E]</td>\n      <td>[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3090</th>\n      <td>extended gravity</td>\n      <td>Exporting firms often enter foreign markets th...</td>\n      <td>[L, F]</td>\n      <td>p00323</td>\n      <td>extended gravity Exporting firms often enter f...</td>\n      <td>export firm often enter foreign market similar...</td>\n      <td>extend gravity export firm often enter foreign...</td>\n      <td>True</td>\n      <td>[F, L]</td>\n      <td>[p01408, p01944]</td>\n      <td>[E, L, D, F, H, R, J, C]</td>\n      <td>[1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3091</th>\n      <td>deforestation in the amazon: a unified framewo...</td>\n      <td>Deforestation is a matter of pressing global c...</td>\n      <td>[L, Q]</td>\n      <td>p01410</td>\n      <td>deforestation in the amazon: a unified framewo...</td>\n      <td>deforestation matter press global concern  yet...</td>\n      <td>deforestation amazon  unify framework estimati...</td>\n      <td>True</td>\n      <td>[Q, L]</td>\n      <td>[]</td>\n      <td>[Q, L]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                                   ngram_range=(1,3), max_features=3000)\n",
    "\n",
    "X_tfidf_ngram = tfidf_vect_ngram.fit_transform(df['cleaned_all_text'])\n",
    "\n",
    "print('X with TfIdf Ngram Vec Shape: ', X_tfidf_ngram.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X with TfIdf Ngram Vec Shape:  (3092, 3000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Auxiliary JEL codes from co-authors\n",
    "aid_tags = df_merged.coded_tags.to_list()\n",
    "aid_tags = np.asarray(aid_tags)\n",
    "aid_tags.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "(3092, 17)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "feats = hstack((X_tfidf_ngram, aid_tags))\n",
    "feats.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "(3092, 3017)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Convert outcome variable to one-hot encoding type\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(df['tags'])\n",
    "pd.DataFrame(y, columns = multilabel.classes_)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "      C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  Z\n0     0  1  1  0  1  0  0  0  0  0  0  0  1  0  0  0  0\n1     0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n2     0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n3     0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0\n4     0  1  1  0  0  0  1  0  0  0  0  0  0  1  0  0  0\n...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n3087  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n3088  0  0  1  0  1  0  0  1  0  0  0  0  0  0  0  0  0\n3089  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n3090  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0\n3091  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0\n\n[3092 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>J</th>\n      <th>K</th>\n      <th>L</th>\n      <th>M</th>\n      <th>N</th>\n      <th>O</th>\n      <th>P</th>\n      <th>Q</th>\n      <th>R</th>\n      <th>Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3087</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3088</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3089</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3090</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3091</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3092 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=123)\n",
    "#X_train, X_test = embeddings[train_inds], embeddings[test_inds]\n",
    "#y_aid_train, y_aid_test = aid_tags[train_inds], aid_tags[test_inds]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# set models\n",
    "sgd = SGDClassifier(class_weight='balanced')\n",
    "lr = LogisticRegression( class_weight='balanced')\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "rf = RandomForestClassifier()\n",
    "naive = MultinomialNB()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# training using tfidf ngram vectorizer\n",
    "for classifier in [sgd, lr, svc]:\n",
    "    train_model(classifier, X_train, y_train, X_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  SGDClassifier\n",
      "Accuracy Score: 0.5005256814626767\n",
      "-----------------------------------\n",
      "Classifier:  LogisticRegression\n",
      "Accuracy Score: 0.5630202323255634\n",
      "-----------------------------------\n",
      "Classifier:  LinearSVC\n",
      "Accuracy Score: 0.5491114701130856\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(solver = 'lbfgs', class_weight='balanced'))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels on test set\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "print(classification_report(y_test, predictions, target_names=multilabel.classes_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.69      0.66       128\n",
      "           D       0.75      0.74      0.74       289\n",
      "           E       0.74      0.79      0.76       139\n",
      "           F       0.81      0.76      0.79        84\n",
      "           G       0.69      0.76      0.72        94\n",
      "           H       0.50      0.64      0.56        86\n",
      "           I       0.70      0.78      0.74        78\n",
      "           J       0.66      0.74      0.70       136\n",
      "           K       0.41      0.42      0.41        31\n",
      "           L       0.58      0.73      0.64       114\n",
      "           M       0.32      0.43      0.37        21\n",
      "           N       0.35      0.39      0.37        28\n",
      "           O       0.58      0.64      0.60       102\n",
      "           P       0.15      0.25      0.19        12\n",
      "           Q       0.73      0.36      0.48        22\n",
      "           R       0.54      0.69      0.61        29\n",
      "           Z       0.35      0.50      0.41        12\n",
      "\n",
      "   micro avg       0.64      0.70      0.67      1405\n",
      "   macro avg       0.56      0.61      0.57      1405\n",
      "weighted avg       0.65      0.70      0.67      1405\n",
      " samples avg       0.68      0.75      0.68      1405\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65       128\n",
      "           1       0.79      0.64      0.71       289\n",
      "           2       0.77      0.71      0.74       139\n",
      "           3       0.84      0.70      0.77        84\n",
      "           4       0.74      0.71      0.72        94\n",
      "           5       0.54      0.56      0.55        86\n",
      "           6       0.75      0.74      0.75        78\n",
      "           7       0.73      0.70      0.71       136\n",
      "           8       0.61      0.35      0.45        31\n",
      "           9       0.61      0.66      0.64       114\n",
      "          10       0.38      0.38      0.38        21\n",
      "          11       0.42      0.36      0.38        28\n",
      "          12       0.64      0.57      0.60       102\n",
      "          13       0.11      0.17      0.13        12\n",
      "          14       0.78      0.32      0.45        22\n",
      "          15       0.66      0.66      0.66        29\n",
      "          16       0.43      0.50      0.46        12\n",
      "\n",
      "   micro avg       0.69      0.63      0.66      1405\n",
      "   macro avg       0.62      0.55      0.57      1405\n",
      "weighted avg       0.70      0.63      0.66      1405\n",
      " samples avg       0.72      0.68      0.66      1405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_pred = (clf.predict_proba(X_test) >= 0.55).astype(int)\n",
    "\n",
    "print(classification_report(y_test, test_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Embeddings\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# applying word2vec\n",
    "df['vec'] = df['cleaned_all_text'].apply(lambda x: get_vec(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of Features Shape:  (3092, 300)\n",
      "Matrix of Coauthor Shape:  (3092, 17)\n"
     ]
    }
   ],
   "source": [
    "# reshaping vector representation\n",
    "X = df['vec'].to_numpy()\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "X = np.concatenate(np.concatenate(X, axis=0), axis = 0).reshape(-1,300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of Features Shape:  (3092, 300)\n",
      "Matrix of Coauthor Shape:  (3092, 17)\n"
     ]
    }
   ],
   "source": [
    "X_emb = pd.DataFrame(X)\n",
    "aid_tags_df = pd.DataFrame(aid_tags)\n",
    "\n",
    "print('Matrix of Features Shape: ', X_emb.shape)\n",
    "print('Matrix of Coauthor Shape: ', aid_tags_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(3092, 317)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding vectors from coauthor\n",
    "feats_emb = pd.concat([X_emb, aid_tags_df], axis = 1)\n",
    "feats_emb.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Convert outcome variable to one-hot encoding type\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(df['tags'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(feats_emb, y, test_size=0.2, random_state=123)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Model (with word2vec)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# set models\n",
    "sgd = SGDClassifier(class_weight='balanced')\n",
    "lr = LogisticRegression( class_weight='balanced')\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "rf = RandomForestClassifier()\n",
    "#naive = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  SGDClassifier\n",
      "Accuracy Score: 0.3397344667538528\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  LogisticRegression\n",
      "Accuracy Score: 0.4701816806421007\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  LinearSVC\n",
      "Accuracy Score: 0.47479998461420103\n",
      "-----------------------------------\n",
      "Classifier:  RandomForestClassifier\n",
      "Accuracy Score: 0.3925686591276252\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training using word2vec representation\n",
    "for classifier in [sgd, lr, svc, rf]:\n",
    "    train_model(classifier, xtrain, ytrain, xtest, ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf2 = OneVsRestClassifier(LinearSVC(class_weight='balanced'))\n",
    "clf2.fit(xtrain, ytrain)\n",
    "\n",
    "# predict the labels on test set\n",
    "\n",
    "predictions2 = clf2.predict(xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.59       128\n",
      "           1       0.72      0.74      0.73       289\n",
      "           2       0.58      0.82      0.68       139\n",
      "           3       0.55      0.74      0.63        84\n",
      "           4       0.51      0.78      0.62        94\n",
      "           5       0.39      0.67      0.49        86\n",
      "           6       0.59      0.86      0.70        78\n",
      "           7       0.61      0.73      0.66       136\n",
      "           8       0.40      0.61      0.48        31\n",
      "           9       0.49      0.76      0.59       114\n",
      "          10       0.14      0.43      0.21        21\n",
      "          11       0.26      0.54      0.35        28\n",
      "          12       0.52      0.71      0.60       102\n",
      "          13       0.10      0.33      0.15        12\n",
      "          14       0.43      0.68      0.53        22\n",
      "          15       0.26      0.69      0.38        29\n",
      "          16       0.24      0.67      0.36        12\n",
      "\n",
      "   micro avg       0.51      0.73      0.60      1405\n",
      "   macro avg       0.43      0.67      0.51      1405\n",
      "weighted avg       0.54      0.73      0.62      1405\n",
      " samples avg       0.55      0.76      0.61      1405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c02g40n7q05p/opt/anaconda3/envs/JELcodes_prediction/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, predictions2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}