{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import ast\r\n",
    "\r\n",
    "import scipy.stats as stats\r\n",
    "from sklearn.utils.fixes import loguniform\r\n",
    "import scipy as sp\r\n",
    "from scipy.sparse import hstack\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
    "\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "#from xgboost import XGBClassifier\r\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\r\n",
    "from sklearn.multiclass import OneVsRestClassifier\r\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\r\n",
    "from skmultilearn.problem_transform import LabelPowerset\r\n",
    "#from utility_functions import *\r\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('wordnet')\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "import re\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mejia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mejia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def Accuracy(y_true, y_pred):\r\n",
    "    \"\"\"\r\n",
    "    Accuracy based on Jaccard Similarity Score\r\n",
    "    :param y_true: ground truth\r\n",
    "    :param y_pred: prediction\r\n",
    "    :return: Jaccard Similarity Score\r\n",
    "    \"\"\"\r\n",
    "    jaccard = np.minimum(y_true, y_pred).sum(axis=1) / np.maximum(y_true, y_pred).sum(axis=1)\r\n",
    "    return jaccard.mean()\r\n",
    "\r\n",
    "\r\n",
    "def print_ml_score(y_test, y_pred, clf):\r\n",
    "    print('Classifier: ', clf.__class__.__name__)\r\n",
    "    print('Accuracy Score: {}'.format(Accuracy(y_test, y_pred)))\r\n",
    "    print(\"-----------------------------------\")\r\n",
    "\r\n",
    "\r\n",
    "def train_model(classifier, feature_vector_train, label_train, feature_vector_test, label_test):\r\n",
    "    # fit the training set on the classifier\r\n",
    "    clf = MultiOutputClassifier(classifier)\r\n",
    "    clf.fit(feature_vector_train, label_train)\r\n",
    "\r\n",
    "    # predict the labels on test set\r\n",
    "    predictions = clf.predict(feature_vector_test)\r\n",
    "    #print(pd.DataFrame(predictions, columns = multilabel.classes_))\r\n",
    "    return print_ml_score(label_test, predictions, classifier)\r\n",
    "\r\n",
    "wnl = WordNetLemmatizer()\r\n",
    "def clean_text(text_series):\r\n",
    "    econ_stopwords = ['model', 'using', 'paper']\r\n",
    "    text_tokens = word_tokenize(text_series)\r\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\r\n",
    "    tokens_without_sw = [word for word in tokens_without_sw if not word in econ_stopwords]\r\n",
    "    tokens_without_sw_lemma = [wnl.lemmatize(word, pos=\"v\") for word in tokens_without_sw if not word in econ_stopwords]\r\n",
    "\r\n",
    "    # removing stopwords and econ stopwords\r\n",
    "    text_series = \" \".join(tokens_without_sw_lemma)\r\n",
    "    # removing double quotes from text\r\n",
    "    text_series = text_series.replace('\"', '')\r\n",
    "    # removing single quotes from text\r\n",
    "    text_series = text_series.replace(\"'\", '')\r\n",
    "    # removing comma from text\r\n",
    "    text_series = text_series.replace(',', '')\r\n",
    "    # removing dot from text\r\n",
    "    text_series = text_series.replace('.', '')\r\n",
    "    # removing double dot from text\r\n",
    "    text_series = text_series.replace(':', '')\r\n",
    "    # removing percentage from text\r\n",
    "    text_series = text_series.replace('%', '')\r\n",
    "    # remove numbers from text\r\n",
    "    text_series = re.sub(r'[0-9]+', '', text_series)\r\n",
    "\r\n",
    "    return text_series"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Notebook parameters\r\n",
    "data_name = 'traning_data_cleaned_v03.csv'\r\n",
    "data_path = 'data/'"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# load data\r\n",
    "\r\n",
    "df = pd.read_csv(data_path + data_name)\r\n",
    "#df.drop(columns=['Unnamed: 0'], inplace=True)\r\n",
    "df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))\r\n",
    "print(df.shape)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3126, 7)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             title_x  \\\n",
       "0     optimal adoption of complementary technologies   \n",
       "1  collateral damage: effects of the japanese ban...   \n",
       "2  endogenous inequality in integrated labor mark...   \n",
       "3  labor-market integration, investment in risky ...   \n",
       "4  unequal societies: income distribution and the...   \n",
       "\n",
       "                                            abstract          tags  \\\n",
       "0  When a production process requires two extreme...  [O, D, G, E]   \n",
       "1  The Japanese banking crisis provides a natural...        [G, E]   \n",
       "2  We consider a market with red and green worker...           [J]   \n",
       "3  This paper presents a general-equilibrium mode...        [J, R]   \n",
       "4  This paper develops a theory of inequality and...  [P, E, I, D]   \n",
       "\n",
       "                         idauthor  \\\n",
       "0            ['p00681', 'p01338']   \n",
       "1            ['p01546', 'p02544']   \n",
       "2  ['p00544', 'p01874', 'p03092']   \n",
       "3                      ['p01266']   \n",
       "4                      ['p04639']   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  optimal adoption of complementary technologies...   \n",
       "1  collateral damage: effects of the japanese ban...   \n",
       "2  endogenous inequality in integrated labor mark...   \n",
       "3  labor-market integration, investment in risky ...   \n",
       "4  unequal societies: income distribution and the...   \n",
       "\n",
       "                                    cleaned_abstract  \\\n",
       "0  production process require two extremely compl...   \n",
       "1  japanese bank crisis provide natural experimen...   \n",
       "2  consider market red green workers  label payof...   \n",
       "3  present general-equilibrium human capital inve...   \n",
       "4  develop theory inequality social contract aim ...   \n",
       "\n",
       "                                    cleaned_all_text  \n",
       "0  optimal adoption complementary technologies pr...  \n",
       "1  collateral damage  effect japanese bank crisis...  \n",
       "2  endogenous inequality integrate labor market t...  \n",
       "3  labor-market integration  investment risky hum...  \n",
       "4  unequal societies  income distribution social ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tags</th>\n",
       "      <th>idauthor</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>cleaned_all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimal adoption of complementary technologies</td>\n",
       "      <td>When a production process requires two extreme...</td>\n",
       "      <td>[O, D, G, E]</td>\n",
       "      <td>['p00681', 'p01338']</td>\n",
       "      <td>optimal adoption of complementary technologies...</td>\n",
       "      <td>production process require two extremely compl...</td>\n",
       "      <td>optimal adoption complementary technologies pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collateral damage: effects of the japanese ban...</td>\n",
       "      <td>The Japanese banking crisis provides a natural...</td>\n",
       "      <td>[G, E]</td>\n",
       "      <td>['p01546', 'p02544']</td>\n",
       "      <td>collateral damage: effects of the japanese ban...</td>\n",
       "      <td>japanese bank crisis provide natural experimen...</td>\n",
       "      <td>collateral damage  effect japanese bank crisis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>endogenous inequality in integrated labor mark...</td>\n",
       "      <td>We consider a market with red and green worker...</td>\n",
       "      <td>[J]</td>\n",
       "      <td>['p00544', 'p01874', 'p03092']</td>\n",
       "      <td>endogenous inequality in integrated labor mark...</td>\n",
       "      <td>consider market red green workers  label payof...</td>\n",
       "      <td>endogenous inequality integrate labor market t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labor-market integration, investment in risky ...</td>\n",
       "      <td>This paper presents a general-equilibrium mode...</td>\n",
       "      <td>[J, R]</td>\n",
       "      <td>['p01266']</td>\n",
       "      <td>labor-market integration, investment in risky ...</td>\n",
       "      <td>present general-equilibrium human capital inve...</td>\n",
       "      <td>labor-market integration  investment risky hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unequal societies: income distribution and the...</td>\n",
       "      <td>This paper develops a theory of inequality and...</td>\n",
       "      <td>[P, E, I, D]</td>\n",
       "      <td>['p04639']</td>\n",
       "      <td>unequal societies: income distribution and the...</td>\n",
       "      <td>develop theory inequality social contract aim ...</td>\n",
       "      <td>unequal societies  income distribution social ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df['keep'] = df.tags.apply(lambda tags: 'Y' not in tags)\r\n",
    "df = df[df.keep == True]\r\n",
    "df['keep'] = df.tags.apply(lambda tags: 'A' not in tags)\r\n",
    "df = df[df.keep == True]\r\n",
    "df['keep'] = df.tags.apply(lambda tags: 'B' not in tags)\r\n",
    "df = df[df.keep == True]\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             title_x  \\\n",
       "0     optimal adoption of complementary technologies   \n",
       "1  collateral damage: effects of the japanese ban...   \n",
       "2  endogenous inequality in integrated labor mark...   \n",
       "3  labor-market integration, investment in risky ...   \n",
       "4  unequal societies: income distribution and the...   \n",
       "\n",
       "                                            abstract          tags  \\\n",
       "0  When a production process requires two extreme...  [O, D, G, E]   \n",
       "1  The Japanese banking crisis provides a natural...        [G, E]   \n",
       "2  We consider a market with red and green worker...           [J]   \n",
       "3  This paper presents a general-equilibrium mode...        [J, R]   \n",
       "4  This paper develops a theory of inequality and...  [P, E, I, D]   \n",
       "\n",
       "                         idauthor  \\\n",
       "0            ['p00681', 'p01338']   \n",
       "1            ['p01546', 'p02544']   \n",
       "2  ['p00544', 'p01874', 'p03092']   \n",
       "3                      ['p01266']   \n",
       "4                      ['p04639']   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  optimal adoption of complementary technologies...   \n",
       "1  collateral damage: effects of the japanese ban...   \n",
       "2  endogenous inequality in integrated labor mark...   \n",
       "3  labor-market integration, investment in risky ...   \n",
       "4  unequal societies: income distribution and the...   \n",
       "\n",
       "                                    cleaned_abstract  \\\n",
       "0  production process require two extremely compl...   \n",
       "1  japanese bank crisis provide natural experimen...   \n",
       "2  consider market red green workers  label payof...   \n",
       "3  present general-equilibrium human capital inve...   \n",
       "4  develop theory inequality social contract aim ...   \n",
       "\n",
       "                                    cleaned_all_text  keep  \n",
       "0  optimal adoption complementary technologies pr...  True  \n",
       "1  collateral damage  effect japanese bank crisis...  True  \n",
       "2  endogenous inequality integrate labor market t...  True  \n",
       "3  labor-market integration  investment risky hum...  True  \n",
       "4  unequal societies  income distribution social ...  True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tags</th>\n",
       "      <th>idauthor</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>cleaned_all_text</th>\n",
       "      <th>keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimal adoption of complementary technologies</td>\n",
       "      <td>When a production process requires two extreme...</td>\n",
       "      <td>[O, D, G, E]</td>\n",
       "      <td>['p00681', 'p01338']</td>\n",
       "      <td>optimal adoption of complementary technologies...</td>\n",
       "      <td>production process require two extremely compl...</td>\n",
       "      <td>optimal adoption complementary technologies pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collateral damage: effects of the japanese ban...</td>\n",
       "      <td>The Japanese banking crisis provides a natural...</td>\n",
       "      <td>[G, E]</td>\n",
       "      <td>['p01546', 'p02544']</td>\n",
       "      <td>collateral damage: effects of the japanese ban...</td>\n",
       "      <td>japanese bank crisis provide natural experimen...</td>\n",
       "      <td>collateral damage  effect japanese bank crisis...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>endogenous inequality in integrated labor mark...</td>\n",
       "      <td>We consider a market with red and green worker...</td>\n",
       "      <td>[J]</td>\n",
       "      <td>['p00544', 'p01874', 'p03092']</td>\n",
       "      <td>endogenous inequality in integrated labor mark...</td>\n",
       "      <td>consider market red green workers  label payof...</td>\n",
       "      <td>endogenous inequality integrate labor market t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labor-market integration, investment in risky ...</td>\n",
       "      <td>This paper presents a general-equilibrium mode...</td>\n",
       "      <td>[J, R]</td>\n",
       "      <td>['p01266']</td>\n",
       "      <td>labor-market integration, investment in risky ...</td>\n",
       "      <td>present general-equilibrium human capital inve...</td>\n",
       "      <td>labor-market integration  investment risky hum...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unequal societies: income distribution and the...</td>\n",
       "      <td>This paper develops a theory of inequality and...</td>\n",
       "      <td>[P, E, I, D]</td>\n",
       "      <td>['p04639']</td>\n",
       "      <td>unequal societies: income distribution and the...</td>\n",
       "      <td>develop theory inequality social contract aim ...</td>\n",
       "      <td>unequal societies  income distribution social ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning: Abstract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering\n",
    "In this step, raw text data will be transformed into feature vectors using different\n",
    "text representation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Convert outcome variable to one-hot encoding type\r\n",
    "multilabel = MultiLabelBinarizer()\r\n",
    "y = multilabel.fit_transform(df['tags'])\r\n",
    "pd.DataFrame(y, columns = multilabel.classes_)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  Z\n",
       "0     0  1  1  0  1  0  0  0  0  0  0  0  1  0  0  0  0\n",
       "1     0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "2     0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
       "3     0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0\n",
       "4     0  1  1  0  0  0  1  0  0  0  0  0  0  1  0  0  0\n",
       "...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n",
       "3087  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "3088  0  0  1  0  1  0  0  1  0  0  0  0  0  0  0  0  0\n",
       "3089  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "3090  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
       "3091  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0\n",
       "\n",
       "[3092 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092 rows Ã— 17 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\r\n",
    "                                   ngram_range=(1,3), max_features=3000)\r\n",
    "\r\n",
    "X_tfidf_ngram = tfidf_vect_ngram.fit_transform(df['cleaned_all_text'])\r\n",
    "\r\n",
    "print('X with TfIdf Ngram Vec Shape: ', X_tfidf_ngram.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X with TfIdf Ngram Vec Shape:  (3092, 3000)\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "xtrain_tfidf_ngram, xtest_tfidf_ngram, ytrain_tfidf_ngram, ytest_tfidf_ngram = train_test_split(X_tfidf_ngram, y,\r\n",
    "                                                                        test_size=0.2,\r\n",
    "                                                                        random_state=123)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "list(zip(list(np.sum(ytest_tfidf_ngram, axis=0)), list(np.sum(ytrain_tfidf_ngram, axis=0))))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(128, 523),\n",
       " (289, 1215),\n",
       " (139, 545),\n",
       " (84, 293),\n",
       " (94, 431),\n",
       " (86, 329),\n",
       " (78, 295),\n",
       " (136, 524),\n",
       " (31, 95),\n",
       " (114, 460),\n",
       " (21, 97),\n",
       " (28, 112),\n",
       " (102, 384),\n",
       " (12, 61),\n",
       " (22, 93),\n",
       " (29, 148),\n",
       " (12, 78)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building Models\n",
    "\n",
    "In this section we test several machine learning models in order to get the best one."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# set models\r\n",
    "sgd = SGDClassifier(class_weight='balanced')\r\n",
    "lr = LogisticRegression(solver = 'lbfgs', class_weight='balanced')\r\n",
    "svc = LinearSVC(class_weight='balanced')\r\n",
    "rf = RandomForestClassifier()\r\n",
    "naive = MultinomialNB()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "eclf1 = VotingClassifier(estimators=[\r\n",
    "        ('lr', lr), ('rf', rf), ('sgd', sgd), ('naive', naive)], voting='hard')\r\n",
    "train_model(eclf1, xtrain_tfidf_ngram, ytrain_tfidf_ngram, xtest_tfidf_ngram, ytest_tfidf_ngram)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier:  VotingClassifier\n",
      "Accuracy Score: 0.49614970382337104\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# training using tfidf ngram vectorizer\r\n",
    "for classifier in [sgd, lr, svc, naive]:\r\n",
    "    train_model(classifier, xtrain_tfidf_ngram, ytrain_tfidf_ngram, xtest_tfidf_ngram, ytest_tfidf_ngram)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier:  SGDClassifier\n",
      "Accuracy Score: 0.5134625740441573\n",
      "-----------------------------------\n",
      "Classifier:  LogisticRegression\n",
      "Accuracy Score: 0.5748038310639281\n",
      "-----------------------------------\n",
      "Classifier:  LinearSVC\n",
      "Accuracy Score: 0.5434571890145395\n",
      "-----------------------------------\n",
      "Classifier:  MultinomialNB\n",
      "Accuracy Score: 0.4272482498653743\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "clf = ClassifierChain(LogisticRegression(solver = 'lbfgs', class_weight='balanced'))\r\n",
    "clf.fit(xtrain_tfidf_ngram, ytrain_tfidf_ngram)\r\n",
    "\r\n",
    "# predict the labels on test set\r\n",
    "\r\n",
    "predictions = clf.predict(xtest_tfidf_ngram)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print_ml_score(ytest_tfidf_ngram, predictions, LogisticRegression(solver = 'lbfgs', class_weight='balanced'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier:  LogisticRegression\n",
      "Accuracy Score: 0.5490698002410442\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.metrics import classification_report\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(classification_report(ytest_tfidf_ngram, predictions))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       128\n",
      "           1       0.76      0.74      0.75       289\n",
      "           2       0.70      0.79      0.74       139\n",
      "           3       0.76      0.83      0.80        84\n",
      "           4       0.66      0.78      0.72        94\n",
      "           5       0.50      0.66      0.57        86\n",
      "           6       0.60      0.83      0.70        78\n",
      "           7       0.62      0.76      0.68       136\n",
      "           8       0.45      0.45      0.45        31\n",
      "           9       0.56      0.75      0.64       114\n",
      "          10       0.20      0.62      0.30        21\n",
      "          11       0.28      0.43      0.34        28\n",
      "          12       0.56      0.65      0.60       102\n",
      "          13       0.10      0.17      0.12        12\n",
      "          14       0.52      0.55      0.53        22\n",
      "          15       0.41      0.69      0.51        29\n",
      "          16       0.17      0.50      0.25        12\n",
      "\n",
      "   micro avg       0.59      0.72      0.65      1405\n",
      "   macro avg       0.50      0.64      0.55      1405\n",
      "weighted avg       0.62      0.72      0.66      1405\n",
      " samples avg       0.64      0.76      0.66      1405\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}